# -*- coding: utf-8 -*-
"""Random_forest_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QM9JFD8dkvpHO4XaxmI5N9O9JjjrBwBb
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

data = pd.read_csv("/content/Predict Price of Airline Tickets.csv")
df = pd.DataFrame(data)

df.head(3)

df.info()

from sklearn import preprocessing
cod = preprocessing.LabelEncoder()
df = df.apply(cod.fit_transform)

df.info()

x = df.iloc[: , 1:-1].values
y = df.iloc[: , -1].values

from sklearn.model_selection import train_test_split 
x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = 0.25 , random_state = 0)

from sklearn.preprocessing import StandardScaler
sc_x = StandardScaler()
x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test)

"""**Decision Tree Model**"""

from sklearn.tree import DecisionTreeRegressor
reg_1 = DecisionTreeRegressor(max_depth= None , min_samples_split= 5 )
reg_1.fit(x_train , y_train)
y_pred = reg_1.predict(x_test)

from sklearn import metrics 
print('MAE:' , metrics.mean_absolute_error(y_test , y_pred))
print('MSE:' , metrics.mean_squared_error(y_test , y_pred))
print('RMSE:' , np.sqrt(metrics.mean_squared_error(y_test , y_pred)))
print('R2:' , metrics.r2_score(y_test , y_pred))

from sklearn.model_selection import KFold , cross_val_score
cv = KFold(n_splits= 35 , shuffle= True , random_state= 100)
score = cross_val_score(reg_1 ,  x ,y , scoring = 'neg_mean_squared_error' , cv = cv , n_jobs = -1)

avg = np.mean(np.absolute(score))
avg

df.head(2)

"""Random Foreset Model"""

from sklearn.ensemble import RandomForestRegressor
reg_2 = RandomForestRegressor(n_estimators= 100 , max_depth= 5 , min_samples_split= 2 )
reg_2.fit(x_train , y_train)
y1_pred = reg_2.predict(x_test)

from sklearn import metrics 
print('MAE:' , metrics.mean_absolute_error(y_test , y1_pred))
print('MSE:' , metrics.mean_squared_error(y_test , y1_pred))
print('RMSE:' , np.sqrt(metrics.mean_squared_error(y_test , y1_pred)))
print('R2:' , metrics.r2_score(y_test , y1_pred))

from sklearn.model_selection import KFold , cross_val_score
cv_1 = KFold(n_splits=30 , shuffle= False)
score_1 = cross_val_score(reg_2 , x , y , scoring = 'neg_mean_squared_error' , cv = cv , n_jobs = -1)

avg = np.mean(np.absolute(score_1))
avg

columns_name= ['Airline' , 'Date_of_Journey' , 'Source' , 'Destination' , 'Route' , 'Dep_Time' , 'Arrival_Time' , 'Duration' , 'Total_Stops' , 
               'Additional_Info' , 'Price']
feature = columns_name
importance = reg_2.feature_importances_
indice = np.argsort(importance)
plt.barh(range(len(indice)) , importance[indice] , color = 'b' , align = 'center' )
plt.yticks(range(len(indice)) , [feature[i] for i in indice])
plt.show()